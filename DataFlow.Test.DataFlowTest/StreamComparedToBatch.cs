using DataFlow.Extensions;
using System.Diagnostics;
using DataFlow.Framework;

namespace DataFlow.Test;

public class StreamVSBArchPlaygroundExamples
{
    /// <summary>
    /// 🎯 Comprehensive Batch vs Stream Pipeline Comparison
    /// </summary>
    public static async Task ComprehensivePipelineComparison()
    {
        Console.WriteLine("🔬 Starting Comprehensive Batch vs Stream Pipeline Comparison...\n");

        // ✅ Generate test data once for both batch and stream processing
        var webLogs = TestDataGenerators.GenerateLogEntries(25).ToList();
        var dbLogs = TestDataGenerators.GenerateLogEntries(15).ToList();
        var cacheLogs = TestDataGenerators.GenerateLogEntries(10).ToList();

        var cpuMetrics = TestDataGenerators.GenerateMetrics(20).ToList();
        var memoryMetrics = TestDataGenerators.GenerateMetrics(15).ToList();
        var networkMetrics = TestDataGenerators.GenerateMetrics(12).ToList();

        var orders = TestDataGenerators.GenerateOrderEvents(15).ToList();
        var sensors = TestDataGenerators.GenerateSensorReadings(12).ToList();

        Console.WriteLine("📊 Generated identical test data for comparison:");
        Console.WriteLine($"   • Logs: {webLogs.Count + dbLogs.Count + cacheLogs.Count} entries");
        Console.WriteLine($"   • Metrics: {cpuMetrics.Count + memoryMetrics.Count + networkMetrics.Count} readings");
        Console.WriteLine($"   • Orders: {orders.Count} events");
        Console.WriteLine($"   • Sensors: {sensors.Count} readings\n");

        // 🔄 Run comparisons for each pipeline
        await CompareLogProcessingPipeline(webLogs, dbLogs, cacheLogs);
        await CompareMetricsMonitoringPipeline(cpuMetrics, memoryMetrics, networkMetrics);
        await CompareMixedDataTypesPipeline(orders, sensors);

        Console.WriteLine("\n🎉 All pipeline comparisons completed successfully!");
    }

    /// <summary>
    /// 📋 Compare Log Processing: Batch vs Stream
    /// </summary>
    private static async Task CompareLogProcessingPipeline(
        List<LogEntry> webLogs,
        List<LogEntry> dbLogs,
        List<LogEntry> cacheLogs)
    {
        Console.WriteLine("📋 COMPARING LOG PROCESSING PIPELINE");
        Console.WriteLine(new string('-', 50));

        // ✅ BATCH PROCESSING
        Console.WriteLine("🔄 Processing logs as BATCH...");
        var batchStopwatch = Stopwatch.StartNew();

        var allLogs = webLogs.Concat(dbLogs).Concat(cacheLogs);
        var batchResults = allLogs
            .Cases(
                log => log.Level == "ERROR" || log.Level == "FATAL",
                log => log.Level == "WARN",
                log => log.Level == "INFO"
            )
            .SelectCase(
                critical => $"🚨 CRITICAL: [{critical.Source}] {critical.Message}",
                warning => $"⚠️ WARNING: [{warning.Source}] {warning.Message}",
                info => $"ℹ️ INFO: [{info.Source}] {info.Message}"
            )
            .AllCases()
            .OrderBy(x => x) // Ensure consistent ordering for comparison
            .ToList();

        batchStopwatch.Stop();
        Console.WriteLine($"✅ Batch processing completed in {batchStopwatch.ElapsedMilliseconds}ms");
        Console.WriteLine($"📊 Batch results: {batchResults.Count} processed items\n");

        // ✅ STREAM PROCESSING
        Console.WriteLine("🌊 Processing logs as STREAM...");
        var streamStopwatch = Stopwatch.StartNew();

        // UPDATED: Added names to each data source.
        var webServerLogs = webLogs.Throttle(1).ToDataSource("WebServerLogs");
        var databaseLogs = dbLogs.Throttle(1).ToDataSource("DatabaseLogs");
        var cacheLogsSource = cacheLogs.Throttle(1).ToDataSource("CacheLogs");

        var merger = new DataFlow<LogEntry>(null, null,
            webServerLogs, databaseLogs, cacheLogsSource
        );

        var streamResults = await merger
            .Cases(
                log => log.Level == "ERROR" || log.Level == "FATAL",
                log => log.Level == "WARN",
                log => log.Level == "INFO"
            )
            .SelectCase(
                critical => $"🚨 CRITICAL: [{critical.Source}] {critical.Message}",
                warning => $"⚠️ WARNING: [{warning.Source}] {warning.Message}",
                info => $"ℹ️ INFO: [{info.Source}] {info.Message}"
            )
            .AllCases()
            .ToList();

        streamResults = streamResults.OrderBy(x => x).ToList(); // Ensure consistent ordering
        streamStopwatch.Stop();

        Console.WriteLine($"✅ Stream processing completed in {streamStopwatch.ElapsedMilliseconds}ms");
        Console.WriteLine($"📊 Stream results: {streamResults.Count} processed items\n");

        // ✅ COMPARISON
        CompareResults("LOG PROCESSING", batchResults, streamResults, batchStopwatch.ElapsedMilliseconds, streamStopwatch.ElapsedMilliseconds);

        // Cleanup
        merger.Dispose();
    }

    /// <summary>
    /// 📊 Compare Metrics Monitoring: Batch vs Stream
    /// </summary>
    private static async Task CompareMetricsMonitoringPipeline(
        List<MetricEntry> cpuMetrics,
        List<MetricEntry> memoryMetrics,
        List<MetricEntry> networkMetrics)
    {
        Console.WriteLine("📊 COMPARING METRICS MONITORING PIPELINE");
        Console.WriteLine(new string('-', 50));

        // ✅ BATCH PROCESSING
        Console.WriteLine("🔄 Processing metrics as BATCH...");
        var batchStopwatch = Stopwatch.StartNew();

        var allMetrics = cpuMetrics.Concat(memoryMetrics).Concat(networkMetrics);
        var batchResults = allMetrics
            .Cases(
                metric => metric.Name == "cpu_usage" && metric.Value > 75,
                metric => metric.Name == "memory_usage" && metric.Value > 85,
                metric => metric.Name == "network_latency" && metric.Value > 180
            )
            .SelectCase(
                cpu => $"🔥 HIGH CPU ALERT: {cpu.Value:F1}% on {cpu.Tags.GetValueOrDefault("host", "unknown")} - Threshold: 75%",
                memory => $"💾 HIGH MEMORY ALERT: {memory.Value:F1}% on {memory.Tags.GetValueOrDefault("host", "unknown")} - Threshold: 85%",
                latency => $"🌐 HIGH LATENCY ALERT: {latency.Value:F1}ms on {latency.Tags.GetValueOrDefault("host", "unknown")} - Threshold: 180ms"
            )
            .AllCases()
            .OrderBy(x => x)
            .ToList();

        batchStopwatch.Stop();
        Console.WriteLine($"✅ Batch processing completed in {batchStopwatch.ElapsedMilliseconds}ms");
        Console.WriteLine($"📊 Batch results: {batchResults.Count} alerts generated\n");

        // ✅ STREAM PROCESSING
        Console.WriteLine("🌊 Processing metrics as STREAM...");
        var streamStopwatch = Stopwatch.StartNew();

        // UPDATED: Added names to each data source.
        var cpuSource = cpuMetrics.Throttle(1).ToDataSource("CpuMetrics");
        var memorySource = memoryMetrics.Throttle(1).ToDataSource("MemoryMetrics");
        var networkSource = networkMetrics.Throttle(1).ToDataSource("NetworkMetrics");

        var merger = new DataFlow<MetricEntry>(null, null,
            cpuSource, memorySource, networkSource
        );

        var streamResults = await merger
            .Cases(
                metric => metric.Name == "cpu_usage" && metric.Value > 75,
                metric => metric.Name == "memory_usage" && metric.Value > 85,
                metric => metric.Name == "network_latency" && metric.Value > 180
            )
            .SelectCase(
                cpu => $"🔥 HIGH CPU ALERT: {cpu.Value:F1}% on {cpu.Tags.GetValueOrDefault("host", "unknown")} - Threshold: 75%",
                memory => $"💾 HIGH MEMORY ALERT: {memory.Value:F1}% on {memory.Tags.GetValueOrDefault("host", "unknown")} - Threshold: 85%",
                latency => $"🌐 HIGH LATENCY ALERT: {latency.Value:F1}ms on {latency.Tags.GetValueOrDefault("host", "unknown")} - Threshold: 180ms"
            )
            .AllCases()
            .ToList();

        streamResults = streamResults.OrderBy(x => x).ToList();
        streamStopwatch.Stop();

        Console.WriteLine($"✅ Stream processing completed in {streamStopwatch.ElapsedMilliseconds}ms");
        Console.WriteLine($"📊 Stream results: {streamResults.Count} alerts generated\n");

        // ✅ COMPARISON
        CompareResults("METRICS MONITORING", batchResults, streamResults, batchStopwatch.ElapsedMilliseconds, streamStopwatch.ElapsedMilliseconds);

        // Cleanup
        merger.Dispose();
    }

    /// <summary>
    /// 🔄 Compare Mixed Data Types Processing: Batch vs Stream
    /// </summary>
    private static async Task CompareMixedDataTypesPipeline(
        List<OrderEvent> orders,
        List<SensorReading> sensors)
    {
        Console.WriteLine("🔄 COMPARING MIXED DATA TYPES PIPELINE");
        Console.WriteLine(new string('-', 50));

        // ✅ BATCH PROCESSING - Orders
        Console.WriteLine("🔄 Processing orders as BATCH...");
        var orderBatchStopwatch = Stopwatch.StartNew();

        var orderBatchResults = orders
            .Cases(
                order => order.EventType == "cancelled",
                order => order.Amount > 500,
                order => order.Status == "failed"
            )
            .SelectCase(
                cancelled => $"❌ CANCELLED ORDER: {cancelled.OrderId} - Amount: ${cancelled.Amount:F2}",
                highValue => $"💎 HIGH VALUE ORDER: {highValue.OrderId} - ${highValue.Amount:F2} - Priority Processing Required",
                failed => $"⚠️ FAILED ORDER: {failed.OrderId} - Needs Investigation"
            )
            .AllCases()
            .OrderBy(x => x)
            .ToList();

        orderBatchStopwatch.Stop();

        // ✅ BATCH PROCESSING - Sensors
        var sensorBatchStopwatch = Stopwatch.StartNew();

        var sensorBatchResults = sensors
            .Cases(
                sensor => sensor.Type == "temperature" && sensor.Value > 30,
                sensor => sensor.Type == "humidity" && sensor.Value > 70,
                sensor => sensor.Type == "pressure" && (sensor.Value < 980 || sensor.Value > 1020)
            )
            .SelectCase(
                temp => $"🌡️ HIGH TEMPERATURE: {temp.Value:F1}°C (Sensor: {temp.SensorId})",
                humidity => $"💧 HIGH HUMIDITY: {humidity.Value:F1}% (Sensor: {humidity.SensorId})",
                pressure => $"🌪️ ABNORMAL PRESSURE: {pressure.Value:F1}hPa (Sensor: {pressure.SensorId})"
            )
            .AllCases()
            .OrderBy(x => x)
            .ToList();

        sensorBatchStopwatch.Stop();

        Console.WriteLine($"✅ Batch processing completed:");
        Console.WriteLine($"   • Orders: {orderBatchResults.Count} results in {orderBatchStopwatch.ElapsedMilliseconds}ms");
        Console.WriteLine($"   • Sensors: {sensorBatchResults.Count} results in {sensorBatchStopwatch.ElapsedMilliseconds}ms\n");

        // ✅ STREAM PROCESSING
        Console.WriteLine("🌊 Processing mixed data as STREAM...");
        var streamStopwatch = Stopwatch.StartNew();

        // UPDATED: Added names to each data source.
        var orderSource = orders.Throttle(1).ToDataSource("OrderEvents");
        var sensorSource = sensors.Throttle(1).ToDataSource("SensorReadings");

        var orderMerger = new DataFlow<OrderEvent>(orderSource);
        var sensorMerger = new DataFlow<SensorReading>(sensorSource);

        var orderTask = orderMerger
            .Cases(
                order => order.EventType == "cancelled",
                order => order.Amount > 500,
                order => order.Status == "failed"
            )
            .SelectCase(
                cancelled => $"❌ CANCELLED ORDER: {cancelled.OrderId} - Amount: ${cancelled.Amount:F2}",
                highValue => $"💎 HIGH VALUE ORDER: {highValue.OrderId} - ${highValue.Amount:F2} - Priority Processing Required",
                failed => $"⚠️ FAILED ORDER: {failed.OrderId} - Needs Investigation"
            )
            .AllCases()
            .ToList();

        var sensorTask = sensorMerger
            .Cases(
                sensor => sensor.Type == "temperature" && sensor.Value > 30,
                sensor => sensor.Type == "humidity" && sensor.Value > 70,
                sensor => sensor.Type == "pressure" && (sensor.Value < 980 || sensor.Value > 1020)
            )
            .SelectCase(
                temp => $"🌡️ HIGH TEMPERATURE: {temp.Value:F1}°C (Sensor: {temp.SensorId})",
                humidity => $"💧 HIGH HUMIDITY: {humidity.Value:F1}% (Sensor: {humidity.SensorId})",
                pressure => $"🌪️ ABNORMAL PRESSURE: {pressure.Value:F1}hPa (Sensor: {pressure.SensorId})"
            )
            .AllCases()
            .ToList();

        await Task.WhenAll(orderTask, sensorTask);

        var orderStreamResults = (await orderTask).OrderBy(x => x).ToList();
        var sensorStreamResults = (await sensorTask).OrderBy(x => x).ToList();

        streamStopwatch.Stop();

        Console.WriteLine($"✅ Stream processing completed in {streamStopwatch.ElapsedMilliseconds}ms");
        Console.WriteLine($"   • Orders: {orderStreamResults.Count} results");
        Console.WriteLine($"   • Sensors: {sensorStreamResults.Count} results\n");

        // ✅ COMPARISONS
        CompareResults("ORDER PROCESSING", orderBatchResults, orderStreamResults,
            orderBatchStopwatch.ElapsedMilliseconds, streamStopwatch.ElapsedMilliseconds);

        CompareResults("SENSOR MONITORING", sensorBatchResults, sensorStreamResults,
            sensorBatchStopwatch.ElapsedMilliseconds, streamStopwatch.ElapsedMilliseconds);

        // Cleanup
        orderMerger.Dispose();
        sensorMerger.Dispose();
    }

    /// <summary>
    /// 🔍 Compare results element by element
    /// </summary>
    private static void CompareResults(string pipelineName, List<string> batchResults, List<string> streamResults, long batchTime, long streamTime)
    {
        Console.WriteLine($"🔍 COMPARISON RESULTS FOR {pipelineName}:");
        Console.WriteLine(new string('=', 60));

        bool countMatch = batchResults.Count == streamResults.Count;
        Console.WriteLine($"📊 Result Count: Batch={batchResults.Count}, Stream={streamResults.Count} {(countMatch ? "✅ MATCH" : "❌ MISMATCH")}");

        var speedup = batchTime == 0 ? "N/A" : $"{(double)streamTime / batchTime:F2}x";
        Console.WriteLine($"⏱️  Performance: Batch={batchTime}ms, Stream={streamTime}ms (Stream is {speedup} of batch time)");

        int mismatches = 0;
        for (int i = 0; i < Math.Max(batchResults.Count, streamResults.Count); i++)
        {
            string batchItem = i < batchResults.Count ? batchResults[i] : "<MISSING>";
            string streamItem = i < streamResults.Count ? streamResults[i] : "<MISSING>";
            if (batchItem != streamItem) mismatches++;
        }

        Console.WriteLine($"\n📈 COMPARISON SUMMARY:");
        Console.WriteLine($"   • Total items compared: {Math.Max(batchResults.Count, streamResults.Count)}");
        Console.WriteLine($"   • Mismatches: {mismatches} {(mismatches > 0 ? "❌" : "✅")}");
        string verdict = mismatches == 0 && countMatch ? "🎉 PERFECT MATCH" : "⚠️ DIFFERENCES DETECTED";
        Console.WriteLine($"   • Verdict: {verdict}");

        Console.WriteLine(new string('-', 60) + "\n");
    }

    /// <summary>
    /// 🎯 Original playground methods (kept for backward compatibility and demonstration)
    /// </summary>
    public static async Task LogProcessingPlayground()
    {
        Console.WriteLine("🚀 Starting Log Processing Pipeline Playground...");
        Console.WriteLine("Simulating real-time logs from multiple sources (WebServer, Database, Cache)...");
        Console.WriteLine(new string('-', 70));

        // Setup throttled data sources to simulate real-time streams
        var webServerLogs = TestDataGenerators.GenerateLogEntries(15).Throttle(150).ToDataSource("WebServerLogs");
        var databaseLogs = TestDataGenerators.GenerateLogEntries(10).Throttle(250).ToDataSource("DatabaseLogs");
        var cacheLogs = TestDataGenerators.GenerateLogEntries(8).Throttle(300).ToDataSource("CacheLogs");

        // Create a DataFlow merger to process all log entries
        var merger = new DataFlow<LogEntry>(null, null, webServerLogs, databaseLogs, cacheLogs);

        try
        {
            // Define the processing pipeline
            var processingTask = merger
                .Cases(
                    log => log.Level == "ERROR" || log.Level == "FATAL", // Case 1: Critical logs
                    log => log.Level == "WARN",                          // Case 2: Warning logs
                    log => log.Level == "INFO"                           // Case 3: Info logs
                )
                .SelectCase(
                    critical => $"🚨 CRITICAL: [{critical.Source}] {critical.Message}",
                    warning => $"⚠️ WARNING: [{warning.Source}] {warning.Message}",
                    info => $"ℹ️ INFO: [{info.Source}] {info.Message}"
                )
                .AllCases()
                .Do();

            await processingTask; // Wait for the pipeline to complete
        }
        finally
        {
            merger.Dispose(); // Clean up resources
        }

        Console.WriteLine(new string('-', 70));
        Console.WriteLine("✅ Log Processing Playground finished.\n");
    }

    public static async Task MetricsMonitoringPlayground()
    {
        Console.WriteLine("📊 Starting Real-time Metrics Monitoring Playground...");
        Console.WriteLine("Simulating a stream of metrics to generate real-time alerts...");
        Console.WriteLine(new string('-', 70));

        // Setup throttled data sources
        var cpuSource = TestDataGenerators.GenerateMetrics().Throttle(200).ToDataSource("CpuMetrics");
        var memorySource = TestDataGenerators.GenerateMetrics().Throttle(300).ToDataSource("MemoryMetrics");
        var networkSource = TestDataGenerators.GenerateMetrics().Throttle(400).ToDataSource("NetworkMetrics");

        var merger = new DataFlow<MetricEntry>(null, null, cpuSource, memorySource, networkSource);

        try
        {
            // Define the alerting pipeline
            var alertingTask = merger
                .Cases(
                    metric => metric.Name == "cpu_usage" && metric.Value > 75,
                    metric => metric.Name == "memory_usage" && metric.Value > 85,
                    metric => metric.Name == "network_latency" && metric.Value > 180
                )
                .SelectCase(
                    cpu => $"🔥 HIGH CPU ALERT: {cpu.Value:F1}% on {cpu.Tags.GetValueOrDefault("host", "unknown")} - Threshold: 75%",
                    memory => $"💾 HIGH MEMORY ALERT: {memory.Value:F1}% on {memory.Tags.GetValueOrDefault("host", "unknown")} - Threshold: 85%",
                    latency => $"🌐 HIGH LATENCY ALERT: {latency.Value:F1}ms on {latency.Tags.GetValueOrDefault("host", "unknown")} - Threshold: 180ms"
                )
                .AllCases()
                .Do();

            await alertingTask;
        }
        finally
        {
            merger.Dispose();
        }

        Console.WriteLine(new string('-', 70));
        Console.WriteLine("✅ Metrics Monitoring Playground finished.\n");
    }

    public static async Task MixedDataTypesPlayground()
    {
        Console.WriteLine("🔄 Starting Mixed Data Types Processing Playground...");
        Console.WriteLine("Running two independent pipelines (Orders & Sensors) concurrently...");
        Console.WriteLine(new string('-', 70));

        // Setup sources for two different data types
        var orderSource = TestDataGenerators.GenerateOrderEvents(15).Throttle(150).ToDataSource("OrderEvents");
        var sensorSource = TestDataGenerators.GenerateSensorReadings(20).Throttle(100).ToDataSource("SensorReadings");

        // Create a separate DataFlow instance for each data type
        var orderMerger = new DataFlow<OrderEvent>(orderSource);
        var sensorMerger = new DataFlow<SensorReading>(sensorSource);

        try
        {
            // Define the Order processing pipeline
            var orderTask = orderMerger
                .Cases(
                    order => order.EventType == "cancelled",
                    order => order.Amount > 500
                )
                .SelectCase(
                    cancelled => $"[Order] ❌ CANCELLED: {cancelled.OrderId}, Amount: ${cancelled.Amount:F2}",
                    highValue => $"[Order] 💎 HIGH VALUE: {highValue.OrderId}, Amount: ${highValue.Amount:F2}"
                )
                .AllCases()
                .Do();

            // Define the Sensor processing pipeline
            var sensorTask = sensorMerger
                .Cases(
                    sensor => sensor.Type == "temperature" && sensor.Value > 30,
                    sensor => sensor.Type == "pressure" && (sensor.Value < 980 || sensor.Value > 1020)
                )
                .SelectCase(
                    temp => $"[Sensor] 🌡️ HIGH TEMP: {temp.Value:F1}°C (ID: {temp.SensorId})",
                    pressure => $"[Sensor] 🌪️ ABNORMAL PRESSURE: {pressure.Value:F1}hPa (ID: {pressure.SensorId})"
                )
                .AllCases()
                .Do();
            // Run both pipelines concurrently
            await Task.WhenAll(orderTask, sensorTask);
        }
        finally
        {
            orderMerger.Dispose();
            sensorMerger.Dispose();
        }

        Console.WriteLine(new string('-', 70));
        Console.WriteLine("✅ Mixed Data Types Playground finished.\n");
    }



    /// <summary>
    /// 🎯 Original playground methods (kept for backward compatibility)
    /// </summary>
    public static async Task RunAllPlaygrounds()
    {
        Console.WriteLine("🎮 DataFlow Framework Interactive Playground");
        Console.WriteLine(new string('=', 50));
        Console.WriteLine();

        try
        {
            // ✅ Run comprehensive comparison first
            await ComprehensivePipelineComparison();

            Console.WriteLine("\n" + new string('=', 50) + "\n");

            // ✅ Optionally run individual playgrounds
            Console.WriteLine("🎯 Running individual playground examples...\n");

            await LogProcessingPlayground();
            await Task.Delay(500);

            await MetricsMonitoringPlayground();
            await Task.Delay(500);

            await MixedDataTypesPlayground();

            Console.WriteLine("\n🎉 All playgrounds and comparisons completed successfully!");
        }
        catch (Exception ex)
        {
            Console.WriteLine($"❌ Error in playground: {ex.Message}");
            Console.WriteLine($"📍 Stack trace: {ex.StackTrace}");
            throw;
        }
        finally
        {
            GC.Collect();
            GC.WaitForPendingFinalizers();
        }
    }

    
}